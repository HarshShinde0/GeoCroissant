#!/usr/bin/env python3
"""
Complete fine-tuning script for Prithvi-EO-1.0-100M on Landslide4Sense dataset
"""

import os
import json
import h5py
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
import torchvision.transforms.functional as F
import numpy as np
from tqdm import tqdm
import matplotlib.pyplot as plt
from sklearn.metrics import f1_score, accuracy_score, precision_recall_fscore_support
import wandb
import requests
from pathlib import Path
import sys
import random

# Add the current directory to path to import prithvi_mae
sys.path.append('.')

# Import the actual Prithvi model
from prithvi_mae import PrithviMAE

class MultispectralTransforms:
    """Custom transforms for multispectral data (14 channels)"""
    
    @staticmethod
    def random_horizontal_flip(img, p=0.5):
        """Random horizontal flip for multispectral images"""
        if random.random() < p:
            return torch.flip(img, [2])  # Flip width dimension
        return img
    
    @staticmethod
    def random_vertical_flip(img, p=0.5):
        """Random vertical flip for multispectral images"""
        if random.random() < p:
            return torch.flip(img, [1])  # Flip height dimension
        return img
    
    @staticmethod
    def random_rotation(img, max_angle=10):
        """Random rotation for multispectral images"""
        angle = random.uniform(-max_angle, max_angle)
        # Apply rotation to each channel
        rotated = torch.zeros_like(img)
        for i in range(img.shape[0]):
            rotated[i] = F.rotate(img[i:i+1], angle, interpolation=F.InterpolationMode.BILINEAR).squeeze(0)
        return rotated
    
    @staticmethod
    def random_brightness_contrast(img, brightness_factor=0.1, contrast_factor=0.1):
        """Random brightness and contrast adjustment for multispectral data"""
        # Apply to each channel independently
        adjusted = torch.zeros_like(img)
        for i in range(img.shape[0]):
            channel = img[i:i+1]
            # Brightness adjustment
            if random.random() < 0.5:
                brightness = random.uniform(1 - brightness_factor, 1 + brightness_factor)
                channel = channel * brightness
            # Contrast adjustment
            if random.random() < 0.5:
                contrast = random.uniform(1 - contrast_factor, 1 + contrast_factor)
                mean = channel.mean()
                channel = (channel - mean) * contrast + mean
            adjusted[i] = channel.squeeze(0)
        return adjusted

class LandslideDataset(Dataset):
    """Landslide4Sense dataset loader using proper metadata paths"""
    
    def __init__(self, metadata_path, split='train', transform=None):
        self.metadata_path = metadata_path
        self.split = split
        self.transform = transform
        
        # Load metadata
        with open(metadata_path, "r") as f:
            self.metadata = json.load(f)
        
        # Get repo path from metadata
        self.repo_path = Path(self.metadata["distribution"][0]["path"])
        
        # Get file listings from metadata
        self.image_files = self.metadata["geocr:fileListing"]["images"][split]
        self.annotation_files = self.metadata["geocr:fileListing"]["annotations"][split]
        
        print(f"Found {len(self.image_files)} images and {len(self.annotation_files)} annotations for {split} split")
    
    def __len__(self):
        return len(self.image_files)
    
    def __getitem__(self, idx):
        # Get file paths from metadata
        image_file = self.repo_path / self.image_files[idx]
        annotation_file = self.repo_path / self.annotation_files[idx]
        
        # Load image data using h5py
        try:
            with h5py.File(image_file, 'r') as f:
                # Get the 'img' dataset
                data = f['img'][:]
                
                # Check shape and transpose if needed
                # Usually HDF5 gives (bands, H, W)
                if data.shape[0] <= 20:  # heuristic for (bands, H, W)
                    image_data = np.transpose(data, (1, 2, 0))  # (H, W, bands)
                else:
                    image_data = data  # already (H, W, bands)
                
        except Exception as e:
            print(f"Error loading image {image_file}: {e}")
            image_data = np.zeros((128, 128, 14))
        
        # Load annotation data using h5py
        try:
            with h5py.File(annotation_file, 'r') as f:
                # Get the 'mask' dataset
                mask_data = f['mask'][:]
        except Exception as e:
            print(f"Error loading annotation {annotation_file}: {e}")
            mask_data = np.zeros((128, 128))
        
        # Convert to torch tensors
        # Image: (H, W, C) -> (C, H, W) for PyTorch
        image_tensor = torch.from_numpy(image_data).float().permute(2, 0, 1)
        
        # Normalize image data per band
        for i in range(image_tensor.shape[0]):
            band = image_tensor[i]
            if band.std() > 0:
                image_tensor[i] = (band - band.mean()) / band.std()
        
        # Annotation: (H, W) -> binary classification
        # Convert to binary: any pixel > 0 is landslide
        annotation_tensor = torch.from_numpy(mask_data).float()
        is_landslide = torch.any(annotation_tensor > 0).float()
        
        # Apply transforms if specified
        if self.transform:
            image_tensor = self.transform(image_tensor)
        
        return {
            'image': image_tensor,
            'label': is_landslide,
            'image_path': str(image_file),
            'annotation_path': str(annotation_file)
        }

class PrithviLandslideClassifier(nn.Module):
    """Prithvi-based classifier for landslide detection using the actual Prithvi model"""
    
    def __init__(self, prithvi_model, num_classes=2):
        super().__init__()
        
        # Use the actual Prithvi model as feature extractor
        self.prithvi = prithvi_model
        
        # Freeze Prithvi parameters for feature extraction
        for param in self.prithvi.parameters():
            param.requires_grad = False
        
        # Select optimal 6 bands for landslide detection:
        # B02 (Blue), B03 (Green), B04 (Red), B07 (NIR), B10 (SWIR), B12 (Slope)
        # These bands provide the most relevant information for landslide detection
        self.band_indices = torch.tensor([1, 2, 3, 7, 10, 12])  # 0-indexed
        
        # Add classification head
        self.classifier = nn.Sequential(
            nn.Linear(768, 512),  # 768 is embed_dim from config
            nn.ReLU(inplace=True),
            nn.Dropout(0.3),
            nn.Linear(512, 256),
            nn.ReLU(inplace=True),
            nn.Dropout(0.3),
            nn.Linear(256, num_classes)
        )
    
    def forward(self, x):
        # Select the optimal 6 bands for landslide detection
        # x shape: [B, 14, H, W] -> [B, 6, H, W]
        x = x[:, self.band_indices, :, :]
        
        # Add time dimension if needed (Prithvi expects 5D: B, C, T, H, W)
        if len(x.shape) == 4:
            x = x.unsqueeze(2)  # Add time dimension
        
        # Get features from Prithvi encoder
        features = self.prithvi.forward_features(x)
        
        # Use the last layer features (CLS token)
        cls_features = features[-1][:, 0, :]  # [B, 1, 768] -> [B, 768]
        
        # Classify
        output = self.classifier(cls_features)
        return output

def load_pretrained_prithvi(checkpoint_path, config):
    """Load pre-trained Prithvi model from checkpoint"""
    print(f"Loading pre-trained Prithvi model from: {checkpoint_path}")
    
    # Create model with config
    model = PrithviMAE(**config)
    
    # Load checkpoint
    checkpoint = torch.load(checkpoint_path, map_location='cpu')
    
    # Remove pos_embed keys as they are fixed
    for k in list(checkpoint.keys()):
        if 'pos_embed' in k:
            del checkpoint[k]
    
    # Load state dict
    model.load_state_dict(checkpoint, strict=False)
    print("Pre-trained weights loaded successfully!")
    
    return model

def train_model(model, train_loader, val_loader, num_epochs=10, device='cuda'):
    """Train the model"""
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.AdamW(model.parameters(), lr=1e-4, weight_decay=0.01)
    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs)
    
    best_f1 = 0.0
    train_losses = []
    val_losses = []
    train_f1s = []
    val_f1s = []
    
    for epoch in range(num_epochs):
        # Training phase
        model.train()
        train_loss = 0.0
        train_preds = []
        train_labels = []
        
        pbar = tqdm(train_loader, desc=f"Epoch {epoch+1}/{num_epochs} [Train]")
        for batch in pbar:
            images = batch['image'].to(device)
            labels = batch['label'].long().to(device)
            
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            
            train_loss += loss.item()
            _, predicted = torch.max(outputs.data, 1)
            train_preds.extend(predicted.cpu().numpy())
            train_labels.extend(labels.cpu().numpy())
            
            pbar.set_postfix({'loss': loss.item()})
        
        scheduler.step()
        
        # Validation phase
        model.eval()
        val_loss = 0.0
        val_preds = []
        val_labels = []
        
        with torch.no_grad():
            for batch in tqdm(val_loader, desc=f"Epoch {epoch+1}/{num_epochs} [Val]"):
                images = batch['image'].to(device)
                labels = batch['label'].long().to(device)
                
                outputs = model(images)
                loss = criterion(outputs, labels)
                val_loss += loss.item()
                
                _, predicted = torch.max(outputs.data, 1)
                val_preds.extend(predicted.cpu().numpy())
                val_labels.extend(labels.cpu().numpy())
        
        # Calculate metrics
        train_f1 = f1_score(train_labels, train_preds, average='weighted')
        val_f1 = f1_score(val_labels, val_preds, average='weighted')
        train_acc = accuracy_score(train_labels, train_preds)
        val_acc = accuracy_score(val_labels, val_preds)
        
        # Store metrics for plotting
        train_losses.append(train_loss/len(train_loader))
        val_losses.append(val_loss/len(val_loader))
        train_f1s.append(train_f1)
        val_f1s.append(val_f1)
        
        print(f"Epoch {epoch+1}/{num_epochs}:")
        print(f"  Train Loss: {train_loss/len(train_loader):.4f}, Train F1: {train_f1:.4f}, Train Acc: {train_acc:.4f}")
        print(f"  Val Loss: {val_loss/len(val_loader):.4f}, Val F1: {val_f1:.4f}, Val Acc: {val_acc:.4f}")
        
        # Save best model
        if val_f1 > best_f1:
            best_f1 = val_f1
            torch.save({
                'epoch': epoch,
                'model_state_dict': model.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
                'best_f1': best_f1,
                'config': {
                    'num_bands': 14,
                    'num_classes': 2
                }
            }, 'best_landslide_model.pth')
            print(f"  New best model saved with F1: {best_f1:.4f}")
        
        # Log to wandb
        if wandb.run:
            wandb.log({
                'epoch': epoch,
                'train_loss': train_loss/len(train_loader),
                'val_loss': val_loss/len(val_loader),
                'train_f1': train_f1,
                'val_f1': val_f1,
                'train_acc': train_acc,
                'val_acc': val_acc,
                'learning_rate': scheduler.get_last_lr()[0]
            })
    
    # Plot training curves
    plot_training_curves(train_losses, val_losses, train_f1s, val_f1s)
    
    return best_f1

def plot_training_curves(train_losses, val_losses, train_f1s, val_f1s):
    """Plot training curves"""
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))
    
    # Loss curves
    ax1.plot(train_losses, label='Train Loss', color='blue')
    ax1.plot(val_losses, label='Val Loss', color='red')
    ax1.set_xlabel('Epoch')
    ax1.set_ylabel('Loss')
    ax1.set_title('Training and Validation Loss')
    ax1.legend()
    ax1.grid(True)
    
    # F1 curves
    ax2.plot(train_f1s, label='Train F1', color='blue')
    ax2.plot(val_f1s, label='Val F1', color='red')
    ax2.set_xlabel('Epoch')
    ax2.set_ylabel('F1 Score')
    ax2.set_title('Training and Validation F1 Score')
    ax2.legend()
    ax2.grid(True)
    
    plt.tight_layout()
    plt.savefig('training_curves.png', dpi=150, bbox_inches='tight')
    print("Training curves saved to: training_curves.png")

def evaluate_model(model, test_loader, device):
    """Evaluate the model on test set"""
    model.eval()
    test_preds = []
    test_labels = []
    test_probs = []
    
    with torch.no_grad():
        for batch in tqdm(test_loader, desc="Evaluating on test set"):
            images = batch['image'].to(device)
            labels = batch['label'].long().to(device)
            
            outputs = model(images)
            probs = torch.softmax(outputs, dim=1)
            _, predicted = torch.max(outputs.data, 1)
            
            test_preds.extend(predicted.cpu().numpy())
            test_labels.extend(labels.cpu().numpy())
            test_probs.extend(probs.cpu().numpy())
    
    # Calculate metrics
    test_f1 = f1_score(test_labels, test_preds, average='weighted')
    test_acc = accuracy_score(test_labels, test_preds)
    precision, recall, f1, support = precision_recall_fscore_support(
        test_labels, test_preds, average='weighted'
    )
    
    print(f"\nTest Set Results:")
    print(f"  Accuracy: {test_acc:.4f}")
    print(f"  F1 Score: {test_f1:.4f}")
    print(f"  Precision: {precision:.4f}")
    print(f"  Recall: {recall:.4f}")
    
    return {
        'accuracy': test_acc,
        'f1': test_f1,
        'precision': precision,
        'recall': recall
    }

def main():
    """Main fine-tuning function"""
    print("Starting Prithvi-EO-1.0-100M fine-tuning on Landslide4Sense dataset")
    print("=" * 70)
    
    # Set device
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"Using device: {device}")
    
    # Initialize wandb
    try:
        wandb.init(
            project="prithvi-landslide-finetuning",
            config={
                "model_type": "prithvi_eo_100m",
                "dataset": "landslide4sense",
                "num_bands": 14,
                "num_classes": 2,
                "img_size": 128,
                "batch_size": 16
            },
            name="prithvi-eo-100m-landslide4sense"
        )
    except:
        print("Wandb not available, continuing without logging")
        wandb.run = None
    
    # Data transforms for multispectral data
    def get_multispectral_transforms():
        """Get transforms for multispectral data"""
        def transform(img):
            # Apply custom multispectral transforms
            img = MultispectralTransforms.random_horizontal_flip(img, p=0.5)
            img = MultispectralTransforms.random_vertical_flip(img, p=0.5)
            img = MultispectralTransforms.random_rotation(img, max_angle=10)
            img = MultispectralTransforms.random_brightness_contrast(img)
            return img
        return transform
    
    transform = get_multispectral_transforms()
    
    # Create datasets using proper metadata path
    print("\nCreating datasets...")
    metadata_path = "/teamspace/studios/this_studio/Landslide4sense.json"
    
    train_dataset = LandslideDataset(metadata_path, split='train', transform=transform)
    val_dataset = LandslideDataset(metadata_path, split='validation')
    test_dataset = LandslideDataset(metadata_path, split='test')
    
    # Create data loaders
    batch_size = 16
    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)
    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2)
    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)
    
    print(f"Train samples: {len(train_dataset)}")
    print(f"Validation samples: {len(val_dataset)}")
    print(f"Test samples: {len(test_dataset)}")
    
    # Initialize model
    print("\nInitializing model...")
    
    # Load pre-trained Prithvi model using the downloaded weights
    prithvi_config = {
        'img_size': 128,
        'patch_size': (1, 16, 16),  # (temporal, height, width)
        'num_frames': 1,  # Single frame for static images
        'in_chans': 6,  # Pre-trained model expects 6 bands
        'embed_dim': 768,
        'depth': 12,
        'num_heads': 12,
        'decoder_embed_dim': 512,
        'decoder_depth': 8,
        'decoder_num_heads': 16,
        'mlp_ratio': 4.0,
        'norm_layer': nn.LayerNorm,
        'norm_pix_loss': False,
        'coords_encoding': None,
        'coords_scale_learn': False,
        'encoder_only': True  # Only use encoder for feature extraction
    }
    
    # Use the downloaded Prithvi model file
    prithvi_checkpoint_path = "Prithvi_EO_V1_100M.pt"
    prithvi_model = load_pretrained_prithvi(prithvi_checkpoint_path, prithvi_config)

    # Create the classifier
    model = PrithviLandslideClassifier(prithvi_model, num_classes=2)
    model = model.to(device)
    
    print(f"Model parameters: {sum(p.numel() for p in model.parameters()):,}")
    print(f"Trainable parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}")
    
    # Train the model
    print("\nStarting training...")
    best_f1 = train_model(model, train_loader, val_loader, num_epochs=15, device=device)
    
    # Load best model for evaluation
    print(f"\nLoading best model (F1: {best_f1:.4f})...")
    checkpoint = torch.load('best_landslide_model.pth')
    model.load_state_dict(checkpoint['model_state_dict'])
    
    # Evaluate on test set
    print("\nEvaluating on test set...")
    test_results = evaluate_model(model, test_loader, device)
    
    # Save final results
    results = {
        'best_f1': best_f1,
        'test_results': test_results,
        'model_config': checkpoint['config']
    }
    
    with open('fine_tuning_results.json', 'w') as f:
        json.dump(results, f, indent=2)
    
    print(f"\nFine-tuning completed!")
    print(f"Best validation F1: {best_f1:.4f}")
    print(f"Test F1: {test_results['f1']:.4f}")
    print(f"Results saved to: fine_tuning_results.json")

if __name__ == "__main__":
    main()
